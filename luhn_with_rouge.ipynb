{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnOgAAS+krqvFB08GXc0jy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/springboardmentor0327/Text_Summarization_Infosys_Internship_Oct2024/blob/Sameer/luhn_with_rouge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT7Umx2mFqys",
        "outputId": "7b64d3c5-21c6-4ff3-cd2e-bca48108a6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sumy\n",
            "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting breadability>=0.1.20 (from sumy)\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.32.3)\n",
            "Collecting pycountry>=18.2.23 (from sumy)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2024.8.30)\n",
            "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: breadability, docopt\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21692 sha256=ace81c17e75bd9a4ea7d198a8b67ecfd167d413f49eb121c496deda5a7b50d3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=625afcfa26331e2480cd4b2447b153a584738243af4f14028d1e28ce7a6e2fe9\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built breadability docopt\n",
            "Installing collected packages: docopt, pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-24.6.1 sumy-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sumy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.luhn import LuhnSummarizer\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7JPimiCFua1",
        "outputId": "7d8f9254-7284-4194-c5c7-ca9daecdbece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.luhn import LuhnSummarizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def luhn_method(text, max_words=30):\n",
        "    # Create a plaintext parser with English tokenization\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "    # Create a Luhn summarizer\n",
        "    summarizer_luhn = LuhnSummarizer()\n",
        "\n",
        "    # Generate all sentences in the summary initially\n",
        "    summary_sentences = summarizer_luhn(parser.document, len(parser.document.sentences))\n",
        "\n",
        "    # Initialize variables for word count\n",
        "    summary = []\n",
        "    current_word_count = 0\n",
        "    min_words = max(0, max_words - 10)  # Default minimum word count, ensures it’s non-negative\n",
        "\n",
        "    # Iterate over sentences, adding them until we reach the max word limit\n",
        "    for sentence in summary_sentences:\n",
        "        sentence_word_count = len(word_tokenize(str(sentence)))\n",
        "\n",
        "        # Check if adding this sentence would exceed max_words\n",
        "        if current_word_count + sentence_word_count > max_words:\n",
        "            break  # Stop if adding the sentence would exceed max_words\n",
        "\n",
        "        # Add the sentence to summary and update the word count\n",
        "        summary.append(str(sentence))\n",
        "        current_word_count += sentence_word_count\n",
        "\n",
        "        # Break if we’ve reached the minimum word count required and are close to max_words\n",
        "        if current_word_count >= min_words:\n",
        "            break\n",
        "\n",
        "    # Convert the summary list to a single string\n",
        "    final_summary = ' '.join(summary)\n",
        "    return final_summary\n",
        "\n",
        "# Example usage\n",
        "text = '''\n",
        "Ad sales boost Time Warner profit\n",
        "\n",
        "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\n",
        "\n",
        "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
        "\n",
        "Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n",
        "\n",
        "Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n",
        "\n",
        "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "print('Original Text:')\n",
        "print(text)\n",
        "print(f\"\\nWord Count (Original): {len(word_tokenize(text))}\\n\")\n",
        "\n",
        "print(\"Summary of Text:\\n\")\n",
        "summary_text = luhn_method(text, max_words=40)\n",
        "print(summary_text)\n",
        "print(f\"\\nWord Count (Summary): {len(word_tokenize(summary_text))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewiy7UxjF_Pq",
        "outputId": "cc1b8a2d-c339-4b55-a442-3f4b201b9970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "\n",
            "Ad sales boost Time Warner profit\n",
            "\n",
            "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\n",
            "\n",
            "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
            "\n",
            "Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n",
            "\n",
            "Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n",
            "\n",
            "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Word Count (Original): 490\n",
            "\n",
            "Summary of Text:\n",
            "\n",
            "Ad sales boost Time Warner profit Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\n",
            "\n",
            "Word Count (Summary): 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROUGE** Module\n"
      ],
      "metadata": {
        "id": "lnBAavmJHQfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMaIRu6OHyBW",
        "outputId": "e03318a8-e9b1-46ec-bc30-cf34604e4e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge"
      ],
      "metadata": {
        "id": "3mOPbYzBH2P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def luhn_method(text, num_sentences):\n",
        "    \"\"\"\n",
        "    Summarize the given text using the Luhn summarization method.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to be summarized.\n",
        "        num_sentences (int): The number of sentences to include in the summary.\n",
        "\n",
        "    Returns:\n",
        "        str: The summarized text.\n",
        "    \"\"\"\n",
        "    # Create a plaintext parser with English tokenization\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "    # Create a Luhn summarizer\n",
        "    summarizer_luhn = LuhnSummarizer()\n",
        "\n",
        "    # Summarize the text, keeping only the specified number of sentences\n",
        "    summary = summarizer_luhn(parser.document, num_sentences)\n",
        "\n",
        "    # Convert the summary to a list of strings\n",
        "    summary_list = [str(sentence) for sentence in summary]\n",
        "\n",
        "    # Join the list of strings into a single string\n",
        "    final_summary = ' '.join(summary_list)\n",
        "\n",
        "    return final_summary\n",
        "\n",
        "def calculate_rouge_score(summary):\n",
        "    \"\"\"\n",
        "    Calculate ROUGE score based on the generated summary itself.\n",
        "\n",
        "    Args:\n",
        "        summary (str): The generated summary.\n",
        "\n",
        "    Returns:\n",
        "        dict: The ROUGE scores.\n",
        "    \"\"\"\n",
        "    rouge = Rouge()\n",
        "    # Use the summary as both reference and prediction\n",
        "    scores = rouge.get_scores(summary, summary)\n",
        "    return scores\n",
        "\n",
        "# Example usage\n",
        "text = '''\n",
        "Samsung was founded by Lee Byung-chul in 1938 as a trading company. Over the next three decades,\n",
        "the group diversified into areas including food processing, textiles, insurance, securities, and retail.\n",
        "Samsung entered the electronics industry in the late 1960s and the construction and shipbuilding industries in the mid-1970s;\n",
        "these areas would drive its subsequent growth. Following Lee's death in 1987,\n",
        "Samsung was separated into five business groups – Samsung Group, Shinsegae Group, CJ Group, Hansol Group, and JoongAng Group.\n",
        "'''\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(text)\n",
        "# Count the number of words before summarizing\n",
        "num_words_before = len(text.split())\n",
        "print(f'Number of words before summarizing: {num_words_before}')\n",
        "\n",
        "# Generate the summary\n",
        "summary = luhn_method(text, num_sentences=2)\n",
        "\n",
        "# Count the number of words after summarizing\n",
        "num_words_after = len(summary.split())\n",
        "print(f'Number of words after summarizing: {num_words_after}')\n",
        "\n",
        "# Print the summary\n",
        "print(\"\\nSummary of Text:\\n\")\n",
        "print(summary)\n",
        "\n",
        "# Calculate and print ROUGE score\n",
        "rouge_scores = calculate_rouge_score(summary)\n",
        "print(\"\\nROUGE Scores:\")\n",
        "print(rouge_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39-zbvSSHVWE",
        "outputId": "8442ba21-4004-46e3-a16f-0be381a20526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "\n",
            "Samsung was founded by Lee Byung-chul in 1938 as a trading company. Over the next three decades, \n",
            "the group diversified into areas including food processing, textiles, insurance, securities, and retail. \n",
            "Samsung entered the electronics industry in the late 1960s and the construction and shipbuilding industries in the mid-1970s; \n",
            "these areas would drive its subsequent growth. Following Lee's death in 1987, \n",
            "Samsung was separated into five business groups – Samsung Group, Shinsegae Group, CJ Group, Hansol Group, and JoongAng Group.\n",
            "\n",
            "Number of words before summarizing: 79\n",
            "Number of words after summarizing: 49\n",
            "\n",
            "Summary of Text:\n",
            "\n",
            "Samsung entered the electronics industry in the late 1960s and the construction and shipbuilding industries in the mid-1970s; these areas would drive its subsequent growth. Following Lee's death in 1987, Samsung was separated into five business groups – Samsung Group, Shinsegae Group, CJ Group, Hansol Group, and JoongAng Group.\n",
            "\n",
            "ROUGE Scores:\n",
            "[{'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}]\n"
          ]
        }
      ]
    }
  ]
}
